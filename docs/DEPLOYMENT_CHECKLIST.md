# Deployment Checklist - Vector-Based Recommendations

## Pre-Deployment

### 1. Code Review
- [x] Database models updated with embedding fields
- [x] AI prompts enhanced with detailed analysis
- [x] Embedding generation added to AI service
- [x] Vector search utilities implemented
- [x] Recommendation logic updated with vector retrieval
- [x] Migration script created

### 2. Local Testing
```bash
# Run migration
python scripts/migrate_add_vector_fields.py

# Verify imports
python -c "from app.core import vector_search; print('OK')"

# Start server
python run.py

# Test endpoints
curl http://localhost:8000/health
```

### 3. Environment Variables
```bash
# Required for embeddings
OPENAI_API_KEY=sk-...

# Or if using Google for everything
GOOGLE_API_KEY=...
LLM_PROVIDER=google
```

---

## AWS Deployment (Postgres + pgvector)

### Step 1: Provision Infrastructure

#### RDS Postgres
```bash
# Create RDS instance
- Engine: PostgreSQL 15+
- Instance: db.t3.micro (dev) or db.t3.small (prod)
- Storage: 20GB SSD
- Enable: Automated backups
- Security group: Allow 5432 from backend
```

#### Enable pgvector
```sql
-- Connect to RDS and run:
CREATE EXTENSION IF NOT EXISTS vector;
```

### Step 2: Deploy Backend

#### Update Environment
```bash
# In .env or ECS task definition
DATABASE_URL=postgresql://user:pass@rds-endpoint:5432/dbname
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...  # if using Gemini
LLM_PROVIDER=google
```

#### Deploy Application
```bash
# Build Docker image
docker build -t dripdirective-backend .

# Push to ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account>.dkr.ecr.us-east-1.amazonaws.com
docker tag dripdirective-backend:latest <account>.dkr.ecr.us-east-1.amazonaws.com/dripdirective:latest
docker push <account>.dkr.ecr.us-east-1.amazonaws.com/dripdirective:latest

# Deploy to ECS/Fargate
# (See AWS_DEPLOYMENT_PLAN.md for full details)
```

### Step 3: Run Migrations

#### Initial Schema Migration
```bash
# SSH to backend container or run task
python scripts/migrate_add_vector_fields.py
```

#### Convert Embeddings to pgvector
```sql
-- Connect to Postgres
-- Convert JSON arrays to native vector type
ALTER TABLE user_profiles 
  ALTER COLUMN profile_embedding TYPE vector(1536) 
  USING profile_embedding::text::vector;

ALTER TABLE wardrobe_items 
  ALTER COLUMN item_embedding TYPE vector(1536) 
  USING item_embedding::text::vector;

ALTER TABLE recommendations 
  ALTER COLUMN recommendation_embedding TYPE vector(1536) 
  USING recommendation_embedding::text::vector;

-- Create optimized indexes
CREATE INDEX idx_wardrobe_embedding ON wardrobe_items 
  USING ivfflat (item_embedding vector_cosine_ops) 
  WITH (lists = 100);

CREATE INDEX idx_recommendation_embedding ON recommendations 
  USING ivfflat (recommendation_embedding vector_cosine_ops) 
  WITH (lists = 50);

-- Optional: index for user profiles if you search them
CREATE INDEX idx_profile_embedding ON user_profiles 
  USING ivfflat (profile_embedding vector_cosine_ops) 
  WITH (lists = 20);
```

### Step 4: Update Vector Search Code (Optional)

If you want to use native pgvector queries instead of Python cosine similarity:

```python
# In app/core/vector_search.py
# Add a check for Postgres and use native vector ops:

def vector_search_wardrobe_items(...):
    # Check if using Postgres with pgvector
    if db.bind.dialect.name == 'postgresql':
        # Use native pgvector query
        from sqlalchemy import func
        results = db.query(
            WardrobeItem,
            (1 - func.cosine_distance(
                WardrobeItem.item_embedding.cast(Vector(1536)),
                query_embedding
            )).label('similarity')
        ).filter(
            # ... filters ...
        ).order_by('similarity DESC').limit(limit).all()
        return [(item, sim) for item, sim in results]
    else:
        # Use Python implementation (SQLite)
        # ... existing code ...
```

### Step 5: Verify Deployment

```bash
# Test health endpoint
curl https://api.yourdomain.com/health

# Test vector search (after processing some items)
curl -X POST https://api.yourdomain.com/api/recommendations/generate \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"query": "casual summer outfit"}'

# Check logs for vector search messages
# Should see: "üîç Using vector search for wardrobe retrieval"
```

---

## Post-Deployment

### 1. Re-process Existing Data
For existing users with data:
```bash
# Trigger reprocessing to generate embeddings
POST /api/ai/process-user-images
POST /api/ai/process-all-wardrobe
```

### 2. Monitor Performance
- Check CloudWatch logs for embedding generation
- Monitor RDS performance metrics
- Track recommendation quality

### 3. Tune Parameters
Based on user feedback, adjust in `app/core/vector_search.py`:
- `lambda_param` (relevance vs diversity balance)
- `min_similarity` (similarity threshold)
- `num_recommendations` (history window)

---

## Rollback Plan

If issues occur:

### Quick Rollback
1. Deploy previous version without vector code
2. Old code ignores new fields (nullable)
3. System works as before

### Data Rollback
```sql
-- If needed, drop new columns
ALTER TABLE user_profiles DROP COLUMN profile_summary_text;
ALTER TABLE user_profiles DROP COLUMN profile_embedding;
ALTER TABLE wardrobe_items DROP COLUMN item_summary_text;
ALTER TABLE wardrobe_items DROP COLUMN item_embedding;
ALTER TABLE recommendations DROP COLUMN recommendation_embedding;
```

---

## Performance Benchmarks

### SQLite (Development)
- Vector search: ~10ms for 50 items
- Embedding generation: ~200ms per text
- Recommendation: ~3-5 seconds total

### Postgres + pgvector (Production)
- Vector search: ~2ms for 1000 items (with index)
- Embedding generation: ~200ms per text
- Recommendation: ~2-3 seconds total

---

## Cost Estimation

### Embeddings (OpenAI text-embedding-3-small)
- $0.02 per 1M tokens
- User profile: ~500 tokens = $0.00001
- Wardrobe item: ~200 tokens = $0.000004
- Per recommendation query: ~100 tokens = $0.000002

### Example Monthly Cost (1000 users)
- Initial processing: 1000 users √ó $0.001 = $1
- 100 items/user: 100,000 items √ó $0.000004 = $0.40
- 10 recs/user/month: 10,000 queries √ó $0.000002 = $0.02
- **Total: ~$1.50/month for embeddings**

(Plus LLM costs for actual recommendations, which are unchanged)

---

## Monitoring

### Key Metrics to Track
- Embedding generation success rate
- Vector search latency
- Recommendation diversity score
- User satisfaction with recommendations
- Repeat rate (should decrease)

### Logs to Monitor
```
üîç Using vector search for wardrobe retrieval
‚úì Found X candidate items via vector search
‚úì Selected Y diverse items after MMR
‚úì Stored recommendation embedding for diversity tracking
```

---

## Troubleshooting

### Issue: No embeddings generated
**Symptom**: Logs show "‚ö†Ô∏è No embedding provider available"

**Solution**: 
- Verify `OPENAI_API_KEY` is set
- Or verify `GOOGLE_API_KEY` if using Gemini
- Check API key is valid

### Issue: Vector search not working
**Symptom**: Recommendations still use all items

**Solution**:
- Check if items have embeddings: `SELECT COUNT(*) FROM wardrobe_items WHERE item_embedding IS NOT NULL`
- Re-process items: `POST /api/ai/process-all-wardrobe`

### Issue: Recommendations too repetitive
**Solution**:
- Lower `lambda_param` (more diversity)
- Increase `num_recommendations` in history check
- Lower `min_similarity` threshold

### Issue: Recommendations not relevant
**Solution**:
- Raise `lambda_param` (more relevance)
- Raise `min_similarity` threshold
- Check if user profile exists and has embedding

---

## Success Criteria

‚úÖ Migration runs without errors
‚úÖ New fields visible in database
‚úÖ Embeddings generated for new items
‚úÖ Vector search finds relevant items
‚úÖ Recommendations show diversity
‚úÖ No repetition in consecutive recommendations
‚úÖ Response times < 5 seconds
‚úÖ User feedback positive

---

## Next Steps

1. ‚úÖ Deploy code
2. ‚úÖ Run migration
3. ‚úÖ Test with sample data
4. ‚¨ú Monitor for 1 week
5. ‚¨ú Collect user feedback
6. ‚¨ú Tune parameters based on data
7. ‚¨ú Consider image embeddings (CLIP) for visual similarity
8. ‚¨ú Add user feedback loop (thumbs up/down)

